# Exercices


## Exercice 1

Calculez le logarithme Ã  base 2 des nombres 1, 2, 8 et 256.

## Exercice 2

<!-- Collet -->

Une source Ã©met 100 symboles par seconde parmi un alphabet de trois symboles $\{A,B,C\}$
dont les probabilitÃ©s respectives sont Ã©gales Ã  $0,8$, $0,15$ et $0,05$.
On souhaite savoir si les messages de cette source peuvent Ãªtre transmis sur un canal binaire
pouvant transmettre sans erreur 95 bits par seconde.

1. Calculez l'auto-information des symboles, puis l'entropie de la source. <!-- 0.884 Sh/symb -->
1. Quel est le dÃ©bit de la source ? <!-- 100 symb/s -->
1. Calculez le taux d'Ã©mission de la source. <!-- 88.4 Sh/s -->
1. Quel est le dÃ©bit du canal ? <!-- 100 bits/s (canal binaire) -->
1. Quelle est la capacitÃ© du canal ? <!-- 100 Sh/s -->
1. La transmission est-elle possible sans erreur ? <!-- Transmission (thÃ©oriquement) possible -->


## Exercice 3

<!-- MacKay, exercices 5.19 et 5.20 -->

1. Le code binaire
   {<code>00</code>, <code>11</code>, <code>0101</code>, <code>111</code>, <code>1010</code>, <code>100100</code>, <code>0110</code>}
   est-il Ã  dÃ©codage unique ?
1. Le code ternaire
   {<code>00</code>, <code>012</code>, <code>0110</code>, <code>0112</code>, <code>100</code>, <code>201</code>, <code>212</code>, <code>22</code>}
   est-il Ã  dÃ©codage unique ?


## Exercice 4

On considÃ¨re une source qui Ã©met quatre symboles, par exemple ğŸ˜€, â˜¹ï¸, ğŸ˜›, ğŸ˜ avec les probabilitÃ©s

$$
p(ğŸ˜€) = 0,4 \quad
p(â˜¹ï¸) = 0,3 \quad
p(ğŸ˜›) = 0,2 \quad
p(ğŸ˜) = 0,1
$$

1. Calculez l'entropie de le source.
2. Pour chacun des codes ci-dessous, indiquez quelles propriÃ©tÃ©s ils vÃ©rifient et calculez leur longueur moyenne.

|Â        |Â   ğŸ˜€ |   Â â˜¹ï¸ |   ğŸ˜› |  Â ğŸ˜ |
| ------ | ---- | ---- | ---- | ---- |
|Â Code 1 |   00 |   01 |   10 |   11 |
|Â Code 2 |    0 |    1 |   10 |   11 |
|Â Code 3 |    0 |   01 |  011 | 0111 |
|Â Code 4 |    1 |   01 |  001 |  000 |


## Exercice 5

<!-- Attention : l'exercice distribuÃ©e en cours cette annÃ©e Ã©tait erronÃ©. Je propose cette nouvelle version -->
<!-- En effet, dans l'ancienne version, je faisais le lien entre longueur d'un code de longueur fixe et entropie, alors qu'il n'y en a pas. -->

Une source $X$ utilise un alphabet de cinq symboles.

1. Combien de bits sont nÃ©cessaires pour rÃ©aliser un code de longueur fixe Ã  dÃ©codage unique ?

On dÃ©cide de transmettre ces symboles en les regroupant deux par deux : cela revient Ã  considÃ©rer une nouvelle source $Y$.

1. Combien y a-t-il de symboles dans l'alphabet de la source $Y$ ?
1. Combien de bits sont nÃ©cessaires pour rÃ©aliser un code de longueur fixe Ã  dÃ©codage unique ?
1. Cette maniÃ¨re de procÃ©der est-elle plus intÃ©ressante que pour la transmission de la source $X$ ?

<!-- % Une source $X$ utilise un alphabet de trois symboles $\{A,B,C\}$
% dont les probabilitÃ©s respectives sont Ã©gales Ã  $0,5$, $0,3$ et $0,2$.
% \begin{questions}
% 1. Calculez l'entropie de la source.
% 1. Combien de bits sont nÃ©cessaires pour rÃ©aliser un code de longueur fixe Ã  dÃ©codage unique ?
% \end{questions}
% On dÃ©cide alors de transmettre ces symboles en les regroupant par groupe de deux :
% cela revient Ã  considÃ©rer une nouvelle source $Y$.
% \begin{questions}
% 1. Combien y a-t-il de symboles dans l'alphabet de la source $Y$ ?
% 1. Calculez l'entropie de la source $Y$.
% 1. Combien de bits sont nÃ©cessaires pour rÃ©aliser un code de longueur fixe Ã  dÃ©codage unique ?
% 1. Cette maniÃ¨re de procÃ©der est-elle plus intÃ©ressante que pour la transmission de la source $X$ ?
% \end{questions} -->

## Exercice 6

<!-- Proakis p. 96 -->

On considÃ¨re l'alphabet dÃ©fini ci-dessous :

| Symbole     | A    | B    | C    | D    | E    | F     | G     |
| ----------- | ---- | ---- | ---- | ---- | ---- | ----- | ----- |
|Â ProbabilitÃ© | 0,35 | 0,30 | 0,20 | 0,10 | 0,04 | 0,005 | 0,005 |

1. Calculez l'auto-information des symboles, puis l'entropie de la source <!-- 2.11 -->
1. DÃ©terminez le code de Huffman associÃ© Ã  la source.
1. Calculez la longueur moyenne du code obtenu. <!-- L = 2.21 -->

## Exercice 7

<!-- Proakis p. 96 -->

MÃªmes questions que l'exercice prÃ©cÃ©dent avec l'alphabet dÃ©fini ci-dessous :

| Symbole     | A    | B    | C    | D    | E    | F     | G     | H     |
| ----------- | ---- | ---- | ---- | ---- | ---- | ----- | ----- | ----- |
|Â ProbabilitÃ© | 0,36 | 0,14 | 0,13 | 0,12 | 0,10 | 0,009 | 0,004 | 0,002 |

<!-- H = 2.63, L = 2.70 -->
